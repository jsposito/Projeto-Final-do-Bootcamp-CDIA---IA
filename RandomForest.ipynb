{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BLUibLY-0pBu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvmSvNPfb5YO"
      },
      "outputs": [],
      "source": [
        "# Célula 1: Importar bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Bibliotecas importadas com sucesso!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 2: Fazer o upload do arquivo bootcamp_train\n",
        "print(\"Por favor, faça o upload do arquivo 'bootcamp_train.csv'\")\n",
        "uploaded_train = files.upload()\n",
        "\n",
        "print(\"\\nUpload do 'bootcamp_train.csv' concluído!\")"
      ],
      "metadata": {
        "id": "W58DSIn90st8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 2.5: Carregar os dados do arquivo para o DataFrame\n",
        "import io\n",
        "\n",
        "# Extrai o nome do arquivo do dicionário 'uploaded_train'\n",
        "train_filename = list(uploaded_train.keys())[0]\n",
        "\n",
        "# Usa o pandas para ler o arquivo carregado e criar o DataFrame 'df_train'\n",
        "df_train = pd.read_csv(io.BytesIO(uploaded_train[train_filename]))\n",
        "\n",
        "print(f\"Arquivo '{train_filename}' carregado com sucesso no DataFrame 'df_train'.\")"
      ],
      "metadata": {
        "id": "LqIH2Syg1wrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hpB6swkJ1HXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 3: Diagnóstico Completo do DataFrame de Treino\n",
        "\n",
        "print(\"Executando diagnóstico completo do arquivo de treino...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# 1. Formato dos dados\n",
        "print(\"Formato dos dados:\")\n",
        "print(\" - df_train:\", df_train.shape)\n",
        "print()\n",
        "\n",
        "# 2. Nomes das colunas\n",
        "print(\"Colunas encontradas:\")\n",
        "print(list(df_train.columns))\n",
        "print()\n",
        "\n",
        "# 3. Tipos de dados (dtypes)\n",
        "print(\"Tipos de dados (dtypes) por coluna:\")\n",
        "print(df_train.dtypes.sort_index())\n",
        "print()\n",
        "\n",
        "# 4. Separação de colunas numéricas e categóricas\n",
        "num_cols = df_train.select_dtypes(include=np.number).columns.tolist()\n",
        "cat_cols = df_train.select_dtypes(exclude=np.number).columns.tolist()\n",
        "print(f\"Colunas Numéricas ({len(num_cols)}):\", num_cols)\n",
        "print(f\"Colunas Categóricas ({len(cat_cols)}):\", cat_cols)\n",
        "print()\n",
        "\n",
        "# 5. Contagem de valores ausentes (NaN)\n",
        "print(\"Colunas com mais valores ausentes:\")\n",
        "missing = df_train.isna().sum().sort_values(ascending=False)\n",
        "print(missing[missing > 0]) # Mostra apenas as colunas que de fato têm valores ausentes\n",
        "print()\n",
        "\n",
        "# 6. Verificação de linhas duplicadas\n",
        "dup = int(df_train.duplicated().sum())\n",
        "print(f\"Linhas duplicadas encontradas: {dup}\")\n",
        "print()\n",
        "\n",
        "# 7. Estatísticas básicas das variáveis numéricas\n",
        "print(\"Estatísticas das variáveis numéricas:\")\n",
        "stats = df_train[num_cols].describe().T[['mean','std','min','max']]\n",
        "print(stats)\n",
        "print()\n",
        "\n",
        "# 8. Cardinalidade das variáveis categóricas (quantos valores únicos)\n",
        "print(\"Cardinalidade das variáveis categóricas:\")\n",
        "card = df_train[cat_cols].nunique().sort_values(ascending=False)\n",
        "print(card)\n",
        "print()\n",
        "\n",
        "# 9. Análise das Colunas-Alvo (Targets)\n",
        "print(\"Análise das Colunas-Alvo:\")\n",
        "# Adaptamos a lista para as colunas reais do nosso projeto\n",
        "TARGET_COLS = [\n",
        "    'falha_maquina',\n",
        "    'FDF (Falha Desgaste Ferramenta)',\n",
        "    'FDC (Falha Dissipacao Calor)',\n",
        "    'FP (Falha Potencia)',\n",
        "    'FTE (Falha Tensao Excessiva)',\n",
        "    'FA (Falha Aleatoria)'\n",
        "]\n",
        "\n",
        "present_targets = [c for c in TARGET_COLS if c in df_train.columns]\n",
        "\n",
        "if present_targets:\n",
        "    print(\"Alvos encontrados:\", present_targets)\n",
        "    for t in present_targets:\n",
        "        vc = df_train[t].value_counts(dropna=False)\n",
        "        total = vc.sum()\n",
        "        print(f\"\\n— Distribuição de '{t}':\")\n",
        "        for k, v in vc.items():\n",
        "            pct = 100.0 * v / total\n",
        "            print(f\"    {str(k):<10}: {v:>6} ({pct:.2f}%)\")\n",
        "else:\n",
        "    print(\"Nenhuma das colunas-alvo do projeto foi encontrada.\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"Diagnóstico concluído.\")"
      ],
      "metadata": {
        "id": "SVXrj2dj1Hrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Limpeza e Preparação dos Dados (Focado no df_train"
      ],
      "metadata": {
        "id": "IR0d2v6N5XgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 4: Limpeza e Preparação dos Dados (Focado no df_train)\n",
        "\n",
        "print(\"Iniciando a limpeza dos dados de treino...\")\n",
        "\n",
        "# 1. Limpar colunas de falha (targets)\n",
        "colunas_para_limpar = [\n",
        "    'falha_maquina',\n",
        "    'FDF (Falha Desgaste Ferramenta)',\n",
        "    'FDC (Falha Dissipacao Calor)',\n",
        "    'FP (Falha Potencia)',\n",
        "    'FTE (Falha Tensao Excessiva)',\n",
        "    'FA (Falha Aleatoria)'\n",
        "]\n",
        "\n",
        "mapa_valores = {\n",
        "    'sim': 1, 'Sim': 1, 'y': 1, '1': 1, 1: 1, True: 1,\n",
        "    'não': 0, 'Não': 0, 'N': 0, '0': 0, 0: 0, False: 0, 'n': 0\n",
        "}\n",
        "\n",
        "# Aplicar a limpeza apenas no df_train\n",
        "for col in colunas_para_limpar:\n",
        "    if col in df_train.columns: # Checa se a coluna existe antes de limpar\n",
        "        df_train[col] = df_train[col].replace(mapa_valores)\n",
        "        # Converte para numérico, tratando erros e preenchendo o que sobrar com 0\n",
        "        df_train[col] = pd.to_numeric(df_train[col], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "print(\"\\nColunas de falha limpas. Verificando 'falha_maquina':\")\n",
        "print(df_train['falha_maquina'].value_counts())\n",
        "\n",
        "# 2. Preencher dados faltantes nas features numéricas\n",
        "numeric_features = ['temperatura_ar', 'temperatura_processo', 'velocidade_rotacional', 'torque', 'desgaste_da_ferramenta']\n",
        "\n",
        "for col in numeric_features:\n",
        "    # Preenche valores faltantes com a mediana da coluna\n",
        "    # Usar a mediana é mais robusto a outliers\n",
        "    mediana = df_train[col].median()\n",
        "    df_train[col].fillna(mediana, inplace=True)\n",
        "\n",
        "print(\"\\nValores nulos preenchidos. Verificando novamente as informações:\")\n",
        "df_train.info()\n",
        "print(\"\\nLimpeza de dados concluída!\")"
      ],
      "metadata": {
        "id": "MS6ywCfP5X2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Análise Exploratória de Dados (EDA) com Dados Limpos"
      ],
      "metadata": {
        "id": "Uvp4iF365YHQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 5: Análise Exploratória de Dados (EDA) com Dados Limpos\n",
        "\n",
        "print(\"Iniciando a Análise Exploratória de Dados...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# 1. Análise do Desbalanceamento de Classes\n",
        "print(\"\\nGráfico 1: Distribuição da 'falha_maquina'\")\n",
        "falha_counts = df_train['falha_maquina'].value_counts()\n",
        "\n",
        "plt.figure(figsize=(7, 5))\n",
        "sns.barplot(x=falha_counts.index, y=falha_counts.values, palette='viridis')\n",
        "plt.title('Distribuição da Falha Geral da Máquina')\n",
        "plt.ylabel('Contagem de Amostras')\n",
        "plt.xticks([0, 1], ['Sem Falha', 'Com Falha'])\n",
        "plt.show()\n",
        "\n",
        "# 2. Contagem por Tipo Específico de Falha\n",
        "print(\"\\nGráfico 2: Contagem por Tipo Específico de Falha\")\n",
        "target_cols = [\n",
        "    'FDF (Falha Desgaste Ferramenta)', 'FDC (Falha Dissipacao Calor)',\n",
        "    'FP (Falha Potencia)', 'FTE (Falha Tensao Excessiva)', 'FA (Falha Aleatoria)'\n",
        "]\n",
        "falhas_especificas = df_train[target_cols].sum().sort_values(ascending=False)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=falhas_especificas.index, y=falhas_especificas.values, palette='crest')\n",
        "plt.title('Contagem de Cada Tipo de Falha Específica')\n",
        "plt.ylabel('Contagem de Amostras')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 3. Distribuição das Variáveis Numéricas\n",
        "print(\"\\nGráfico 3: Distribuição das Variáveis Numéricas\")\n",
        "# A lista 'numeric_features' foi definida na célula de limpeza\n",
        "plt.figure(figsize=(15, 10))\n",
        "df_train[numeric_features].hist(bins=30, color='skyblue', layout=(2, 3), ax=plt.gca())\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 4. Matriz de Correlação\n",
        "print(\"\\nGráfico 4: Matriz de Correlação entre Variáveis\")\n",
        "# Vamos correlacionar as features numéricas com a falha geral\n",
        "cols_for_corr = numeric_features + ['falha_maquina']\n",
        "correlation_matrix = df_train[cols_for_corr].corr()\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Matriz de Correlação')\n",
        "plt.show()\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"Análise Exploratória concluída.\")"
      ],
      "metadata": {
        "id": "5i_EdSBI5YZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pré-processamento e Divisão dos Dados"
      ],
      "metadata": {
        "id": "J3R-W__36EJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 6: Pré-processamento e Divisão dos Dados\n",
        "\n",
        "print(\"Iniciando o pré-processamento e a divisão dos dados...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# 1. Definir as colunas de features (X) e de targets (y)\n",
        "features = ['tipo', 'temperatura_ar', 'temperatura_processo', 'velocidade_rotacional', 'torque', 'desgaste_da_ferramenta']\n",
        "target_cols = [\n",
        "    'FDF (Falha Desgaste Ferramenta)', 'FDC (Falha Dissipacao Calor)',\n",
        "    'FP (Falha Potencia)', 'FTE (Falha Tensao Excessiva)', 'FA (Falha Aleatoria)'\n",
        "]\n",
        "\n",
        "X = df_train[features]\n",
        "y = df_train[target_cols]\n",
        "\n",
        "\n",
        "# 2. Criar o pipeline de pré-processamento com ColumnTransformer\n",
        "# Esta ferramenta aplica diferentes transformações para diferentes tipos de colunas.\n",
        "\n",
        "# Separa as features em dois grupos: numéricas e categóricas\n",
        "categorical_features = ['tipo']\n",
        "numerical_features = ['temperatura_ar', 'temperatura_processo', 'velocidade_rotacional', 'torque', 'desgaste_da_ferramenta']\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        # Etapa 'num': Aplica StandardScaler às colunas numéricas\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        # Etapa 'cat': Aplica OneHotEncoder à coluna categórica\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ])\n",
        "\n",
        "\n",
        "# 3. Dividir os dados em conjuntos de Treino e Validação\n",
        "# Usamos 80% para treino e 20% para validação.\n",
        "# 'stratify' garante que a proporção de falhas seja a mesma em ambos os conjuntos.\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df_train['falha_maquina']\n",
        ")\n",
        "\n",
        "print(\"Pipeline de pré-processamento criado.\")\n",
        "print(\"Dados divididos em conjuntos de treino e validação:\")\n",
        "print(f\" - Tamanho do conjunto de treino (X_train): {X_train.shape}\")\n",
        "print(f\" - Tamanho do conjunto de validação (X_val): {X_val.shape}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"Pré-processamento concluído. Os dados estão prontos para o treinamento.\")"
      ],
      "metadata": {
        "id": "PTQh95cv6EbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Treinamento do Modelo"
      ],
      "metadata": {
        "id": "H4T1MJVp65NK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 7: Treinamento do Modelo de Machine Learning\n",
        "\n",
        "print(\"Iniciando a fase de treinamento do modelo...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# 1. Definir o classificador base\n",
        "# Usamos RandomForestClassifier, um modelo robusto para dados tabulares.\n",
        "# 'class_weight=\"balanced\"' ajuda o modelo a lidar com o desbalanceamento de classes.\n",
        "base_classifier = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
        "\n",
        "# 2. Definir a estratégia para o problema multirrótulo\n",
        "# O MultiOutputClassifier treina um classificador separado para cada tipo de falha.\n",
        "multi_output_model = MultiOutputClassifier(estimator=base_classifier, n_jobs=-1)\n",
        "\n",
        "# 3. Criar o pipeline final que junta o pré-processamento e o modelo\n",
        "# Este é o nosso sistema completo e encapsulado.\n",
        "model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                 ('classifier', multi_output_model)])\n",
        "\n",
        "# 4. Treinar o modelo com os dados de treino!\n",
        "# O comando .fit() inicia o processo de aprendizado.\n",
        "print(\"Treinando o modelo com os dados de treino... Isso pode levar alguns instantes.\")\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"Treinamento concluído!\")"
      ],
      "metadata": {
        "id": "P3LZCDxo659B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avaliação do Modelo"
      ],
      "metadata": {
        "id": "sz9gp6p-6-di"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 8: Avaliação do Desempenho no Conjunto de Validação\n",
        "\n",
        "print(\"Iniciando a avaliação do modelo no conjunto de validação...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# 1. Fazer previsões nos dados de validação\n",
        "y_pred_val = model_pipeline.predict(X_val)\n",
        "\n",
        "# 2. Gerar o Relatório de Classificação para análise de métricas\n",
        "print(\"Relatório de Classificação:\")\n",
        "print(classification_report(y_val, y_pred_val, target_names=target_cols, zero_division=0))\n",
        "\n",
        "\n",
        "# 3. Calcular a métrica AUC-ROC de forma robusta\n",
        "# (Lida com o caso de falhas extremamente raras)\n",
        "print(\"Calculando AUC-ROC Score...\")\n",
        "y_proba_val = model_pipeline.predict_proba(X_val)\n",
        "\n",
        "probabilities = []\n",
        "for p in y_proba_val:\n",
        "    if p.shape[1] == 2:\n",
        "        probabilities.append(p[:, 1]) # Probabilidade da classe 1 (falha)\n",
        "    else:\n",
        "        # Se só há uma coluna, a prob da classe 1 é sempre 0.\n",
        "        probabilities.append(np.zeros(p.shape[0]))\n",
        "\n",
        "y_proba_val_reformatted = np.array(probabilities).T\n",
        "\n",
        "try:\n",
        "    auc_score = roc_auc_score(y_val, y_proba_val_reformatted, average='weighted')\n",
        "    print(f\"\\nAUC-ROC Score (Média Ponderada): {auc_score:.4f}\")\n",
        "except ValueError as e:\n",
        "    print(f\"\\nNão foi possível calcular o AUC Score. Motivo: {e}\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"Avaliação concluída.\")"
      ],
      "metadata": {
        "id": "vbDoTkOW7A4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 8: Avaliação do Desempenho no Conjunto de Validação\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(\"Iniciando a avaliação do modelo no conjunto de validação...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "\n",
        "# 1. Fazer previsões nos dados de validação\n",
        "y_pred_val = model_pipeline.predict(X_val)\n",
        "\n",
        "# 2. Gerar o Relatório de Classificação para análise de métricas\n",
        "print(\"Relatório de Classificação:\")\n",
        "print(classification_report(y_val, y_pred_val, target_names=target_cols, zero_division=0))\n",
        "\n",
        "# (O código para AUC Score permanece o mesmo, pode ser incluído aqui se desejar)\n",
        "# ...\n",
        "\n",
        "# --- NOVO: Visualização com Matrizes de Confusão ---\n",
        "print(\"\\nGráfico: Matrizes de Confusão por Tipo de Falha\")\n",
        "\n",
        "# Criamos uma figura para organizar os 5 gráficos\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
        "axes = axes.flatten() # Transforma a grade 2x3 em uma lista de 6 eixos\n",
        "\n",
        "for i, col in enumerate(target_cols):\n",
        "    # Calcula a matriz de confusão para cada tipo de falha\n",
        "    cm = confusion_matrix(y_val[col], y_pred_val[:, i])\n",
        "\n",
        "    # Define os rótulos para os quadrados da matriz\n",
        "    labels = [['Verdadeiro Negativo\\n'+str(cm[0,0])], ['Falso Positivo\\n'+str(cm[0,1])],\n",
        "              ['Falso Negativo\\n'+str(cm[1,0])], ['Verdadeiro Positivo\\n'+str(cm[1,1])]]\n",
        "\n",
        "    # Formata os labels para exibição\n",
        "    label_text = (np.asarray(labels)).reshape(2,2)\n",
        "\n",
        "    # Plota a matriz como um heatmap\n",
        "    sns.heatmap(cm, annot=label_text, fmt='', cmap='Blues', ax=axes[i], cbar=False)\n",
        "\n",
        "    axes[i].set_title(col)\n",
        "    axes[i].set_ylabel('Rótulo Verdadeiro')\n",
        "    axes[i].set_xlabel('Rótulo Previsto')\n",
        "\n",
        "# Oculta o último eixo que não foi usado\n",
        "axes[5].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"Avaliação concluída.\")"
      ],
      "metadata": {
        "id": "48zOCswV9tFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2ZXsak89-lY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 9: Otimização de Hiperparâmetros com GridSearchCV\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "print(\"Iniciando a otimização de hiperparâmetros com GridSearchCV...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# 1. Definir o pipeline (o mesmo de antes, sem o treinamento)\n",
        "# Nosso pipeline já contém o pré-processador e a estrutura do modelo.\n",
        "base_classifier = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "multi_output_model = MultiOutputClassifier(estimator=base_classifier, n_jobs=-1)\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('classifier', multi_output_model)])\n",
        "\n",
        "# 2. Definir a grade de parâmetros para testar (uma grade \"curta\")\n",
        "# Usamos a sintaxe 'nome_do_passo__parametro_do_estimador__parametro_final'\n",
        "param_grid = {\n",
        "    'classifier__estimator__n_estimators': [100, 150],       # Número de árvores na floresta\n",
        "    'classifier__estimator__max_depth': [10, 20],           # Profundidade máxima de cada árvore\n",
        "    'classifier__estimator__min_samples_leaf': [5, 10]      # Mínimo de amostras em um nó folha\n",
        "}\n",
        "\n",
        "# 3. Configurar o GridSearchCV\n",
        "# 'cv=3' significa que ele usará validação cruzada com 3 folds.\n",
        "# 'scoring' define a métrica que ele tentará otimizar. 'f1_weighted' é boa para nosso caso.\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=pipeline,\n",
        "    param_grid=param_grid,\n",
        "    scoring='f1_weighted',\n",
        "    cv=3,\n",
        "    n_jobs=-1, # Usa todos os processadores disponíveis\n",
        "    verbose=1  # Mostra o progresso\n",
        ")\n",
        "\n",
        "# 4. Executar a busca pelos melhores parâmetros\n",
        "print(\"Executando a busca em grade... Isso pode levar vários minutos.\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# 5. Exibir os melhores parâmetros encontrados\n",
        "print(\"\\nMelhores parâmetros encontrados:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "\n",
        "# 6. Avaliar o MELHOR modelo encontrado pelo GridSearch\n",
        "print(\"\\n--- Avaliação do Modelo Otimizado no Conjunto de Validação ---\")\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred_best = best_model.predict(X_val)\n",
        "\n",
        "print(\"\\nRelatório de Classificação (Modelo Otimizado):\")\n",
        "print(classification_report(y_val, y_pred_best, target_names=target_cols, zero_division=0))\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"Otimização e avaliação concluídas.\")"
      ],
      "metadata": {
        "id": "823PTcCT-ltL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hMBIIx8r-8mW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Célula 10: Geração do Arquivo de Submissão Final com o Modelo Otimizado\n",
        "\n",
        "print(\"Iniciando a etapa final: Geração do arquivo de submissão...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# 1. Fazer o upload do arquivo de teste\n",
        "print(\"Por favor, faça o upload do arquivo 'bootcamp_test.csv'\")\n",
        "try:\n",
        "    # Limpa uploads anteriores para evitar confusão\n",
        "    files.clear()\n",
        "    uploaded_test = files.upload()\n",
        "    test_filename = list(uploaded_test.keys())[0]\n",
        "    df_test = pd.read_csv(io.BytesIO(uploaded_test[test_filename]))\n",
        "    print(f\"\\nArquivo '{test_filename}' carregado com sucesso.\")\n",
        "\n",
        "    # 2. Limpar os dados de teste (aplicar as mesmas transformações do treino)\n",
        "    # É CRUCIAL que o teste passe pela mesma limpeza de features que o treino.\n",
        "    print(\"\\nLimpando os dados de teste...\")\n",
        "    for col in numeric_features:\n",
        "        # Preenche valores faltantes com a MEDIANA DO CONJUNTO DE TREINO para evitar data leakage\n",
        "        mediana = df_train[col].median()\n",
        "        df_test[col].fillna(mediana, inplace=True)\n",
        "    print(\"Limpeza concluída.\")\n",
        "\n",
        "\n",
        "    # 3. Usar o MELHOR modelo encontrado pelo GridSearchCV para prever as PROBABILIDADES\n",
        "    print(\"\\nUsando o modelo otimizado para gerar as previsões...\")\n",
        "    best_model = grid_search.best_estimator_\n",
        "    X_test = df_test[features]\n",
        "\n",
        "    test_probabilities = best_model.predict_proba(X_test)\n",
        "\n",
        "\n",
        "    # 4. Criar e formatar o DataFrame de submissão\n",
        "    submission_df = pd.DataFrame()\n",
        "    submission_df['id'] = df_test['id']\n",
        "\n",
        "    probabilities_submission = []\n",
        "    for p in test_probabilities:\n",
        "        if p.shape[1] == 2:\n",
        "            probabilities_submission.append(p[:, 1])\n",
        "        else:\n",
        "            probabilities_submission.append(np.zeros(p.shape[0]))\n",
        "\n",
        "    for i, col in enumerate(target_cols):\n",
        "        submission_df[col] = probabilities_submission[i]\n",
        "\n",
        "\n",
        "    # 5. Salvar e baixar o arquivo de submissão final\n",
        "    submission_df.to_csv('submission.csv', index=False)\n",
        "    print(\"\\nArquivo 'submission.csv' final gerado com sucesso!\")\n",
        "    display(submission_df.head())\n",
        "\n",
        "    print(\"\\nIniciando o download do arquivo...\")\n",
        "    files.download('submission.csv')\n",
        "    print(\"-\" * 50)\n",
        "    print(\"Processo concluído!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nOcorreu um erro. Certifique-se de que o upload foi concluído. Erro: {e}\")"
      ],
      "metadata": {
        "id": "Rc5CLsKt-83v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}